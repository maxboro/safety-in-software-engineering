
## Risk Analysis and Prioritization

Risk analysis turns a hazard list into a decision tool: it helps you compare scenarios, decide what “enough safety” means for your context, and pick the next engineering actions with the highest safety return.

### Risk estimation approaches

Risk is commonly treated as a combination of **severity of harm** and **likelihood** (sometimes also including exposure/controllability/detectability, depending on the domain and method). Many standards and handbooks allow multiple levels of rigor—**qualitative, semi-quantitative, and quantitative**—chosen based on decision needs and available evidence. ([csrc.nist.gov][1])

#### Qualitative (risk matrices)

A qualitative approach uses **categories** (e.g., severity: minor/major/catastrophic; likelihood: rare/possible/likely) and combines them in a **risk matrix** to assign a **risk rank** or class. NASA’s system safety requirements, for example, use a “Risk Assessment Code (RAC)” derived from severity and probability and explicitly use it to **prioritize corrective actions**. ([nodis3.gsfc.nasa.gov][2])

**Strengths**

* Fast; works when data is scarce.
* Good for early design and for aligning stakeholders on what “bad” looks like.

**Limitations**

* Coarse bins can hide meaningful differences (two risks can land in the same cell but be very different).
* Category boundaries and scoring rules can drive outcomes as much as the underlying reality.
* Best used as a *ranking and discussion tool*, not a precise measurement.

#### Semi-quantitative

Semi-quantitative methods keep the matrix idea but use **numbers as scores** (e.g., 1–5 for likelihood and severity) or use ordinal scales with weights. ISO/IEC 31010 (risk assessment techniques) explicitly recognizes qualitative and semi-quantitative methods as normal ways to **rank actions and set priorities**, taking existing controls into account. ([isa.org.jm][3])

**When it helps**

* You need more granularity than pure qualitative, but you still lack solid statistical data.
* You want consistent triage rules across teams or releases.

**Caution**

* The numbers can look “scientific” while still being largely judgment-based. Treat the output as **relative ranking**, not an absolute probability.

#### Quantitative

Quantitative approaches estimate numeric probabilities/frequencies and consequences (e.g., expected fatalities per year, expected loss per hour, probability of dangerous failure on demand). Functional safety practice often links “tolerable risk” to required **risk reduction**; IEC material explains that higher Safety Integrity Levels (SIL) correspond to higher risk reduction and can be expressed with quantified target failure measures. ([assets.iec.ch][4])

**When it’s worth it**

* High-severity outcomes where decisions justify the cost (e.g., aerospace, medical, industrial control).
* You have usable evidence (field data, test data, reliability models) and you need to compare costly alternatives.

**Common trap**

* “Precision without accuracy”: producing detailed numbers from weak assumptions. If evidence is thin, a well-argued qualitative ranking may be more honest and more useful.

---

### Risk controls

Once risks are ranked, you choose **controls**. A widely used framing is the **hierarchy of controls**—more effective controls reduce risk at the source; less effective ones depend on correct operation, detection, or human compliance. OSHA summarizes the hierarchy as: **elimination, substitution, engineering controls, administrative controls, PPE**, ordered from most to least effective. ([osha.gov][5])

For software-intensive systems, you can translate this into control types:

#### Elimination

Remove the hazardous scenario entirely.

* Remove a dangerous feature/mode.
* Change system boundary so the software never commands the hazardous actuator.
* Constrain the Operational Design Domain (ODD): “system must not operate in X conditions.”

#### Reduction (design/engineering)

Make the scenario less likely or less severe by design.

* Simplify state machines; reduce concurrency; reduce coupling.
* Use proven-safe patterns: interlocks, permissives, invariants, deterministic scheduling where needed.
* Add physical/architectural separation (e.g., safety channel independent of non-safety channel).

#### Detection

Increase the chance you notice the hazardous condition early.

* Plausibility checks, limit checks, heartbeat monitoring, watchdogs.
* Cross-checks between redundant sensors/estimators.
* Runtime monitors for timing overruns, queue growth, memory pressure.

#### Mitigation (limit consequence)

If it happens, limit harm.

* Safe-state transitions, controlled shutdown, degraded mode with bounded outputs.
* Rate limiters, soft limits + hard limits, emergency stop paths.

#### Procedural / administrative controls

Reduce risk by shaping human actions and operational practice (useful but weaker because they rely on training, compliance, and organizational health).

* Operational checklists, maintenance procedures, release gates, code review policies.
* “Two-person rule” for safety-critical configuration changes.

A practical rule: **prefer controls that don’t depend on perfect detection or perfect operator behavior**, and treat procedural controls as supplements when design controls are not reasonably practicable. ([osha.gov][5])

---

### Defining “acceptable risk”

“Acceptable” rarely means “zero.” Many safety regimes use a notion of **tolerable risk** and require that risk be reduced to a level that is **as low as reasonably practicable**.

#### ALARP / SFAIRP (high-level)

In UK safety law practice, duty-holders are required to reduce risk **“so far as reasonably practicable” (SFAIRP)**; HSE guidance discusses SFAIRP and references established legal interpretation (e.g., Edwards v National Coal Board) in terms of balancing risk reduction against what is reasonably practicable. ([hse.gov.uk][6])

**ALARP** (“as low as reasonably practicable”) is commonly used to express the same general idea: keep reducing risk until further reduction would require cost/effort that is **grossly disproportionate** to the safety benefit. (How you justify this depends on domain and regulator expectations.) ([hse.gov.uk][6])

For a software team, “acceptable risk” should be documented as:

* The **risk acceptance criteria** (what severity/likelihood combinations are intolerable, tolerable with justification, or broadly acceptable).
* The **required risk reduction** (what must be implemented before release/operation).
* The **evidence expectation** (tests, analysis, reviews, operational monitoring) proportional to severity.

---

### Choosing what to do first

Prioritization is where risk analysis becomes engineering work. A defensible ordering usually combines (1) severity, (2) uncertainty, and (3) the strength of current controls.

#### 1) High-severity scenarios first

If consequences include **loss of life, severe injury, major property damage**, treat them as “must address” even if likelihood seems low—because likelihood estimates are often fragile early on.

Practical triage:

* **Catastrophic severity + any plausible path** → design constraints, independent safety mechanisms, and strong evidence before release.

#### 2) Unknowns and weak evidence

Uncertainty is itself a risk amplifier. NIST’s risk assessment guidance emphasizes that risk assessment depends on the analysis of factors and the relationships among them, and that the chosen approach (qualitative/semi-quantitative/quantitative) should match the decision and evidence context. ([csrc.nist.gov][1])

Operationally:

* If you can’t justify likelihood, prioritize actions that **reduce uncertainty** (targeted tests, fault injection, field telemetry) *and* actions that reduce consequence if you’re wrong.

#### 3) Weak detectability and poor controllability

Scenarios that you can’t reliably detect or that operators can’t reliably control deserve earlier attention because they defeat “respond when it happens” strategies.

* If detection is unreliable, prioritize **prevention** (eliminate/reduce) over “detect and mitigate.”

#### 4) High coupling and common-cause failure risk

Coupled subsystems create cascades: a single bug (or shared dependency) triggers multiple hazards. Prioritize:

* Architectural separation (independence between safety functions and non-safety functions).
* Removal of single points of failure, especially shared services and shared configuration.

#### 5) Fix the riskiest *control gaps*, not the loudest bugs

Use a “gap lens”:

* What scenarios have **no effective control** (or only procedural controls)?
* Where does the design rely on assumptions that are likely to be violated?
* Which hazards become dangerous under realistic degraded modes?

#### A simple prioritization worksheet (software-friendly)

For each hazard scenario:

1. Severity (qualitative category)
2. Likelihood (qualitative category + confidence)
3. Detectability (good / partial / poor)
4. Coupling/common-cause potential (low / medium / high)
5. Current controls (eliminate / reduce / detect / mitigate / procedural)
6. Resulting priority rule:

   * **P0:** high severity OR poor detectability OR high coupling with weak controls
   * **P1:** medium severity with moderate uncertainty/controls
   * **P2:** low severity and strong controls

This keeps decisions explainable and aligns with the general idea of using qualitative or semi-quantitative ranking to prioritize actions while considering existing controls. ([isa.org.jm][3])

[1]: https://csrc.nist.gov/pubs/sp/800/30/r1/final?utm_source=chatgpt.com "SP 800-30 Rev. 1, Guide for Conducting Risk Assessments"
[2]: https://nodis3.gsfc.nasa.gov/displayCA.cfm?Internal_ID=N_PR_8715_0003_&page_name=Chapter3&utm_source=chatgpt.com "CHAPTER 3. System Safety - NODIS Library"
[3]: https://www.isa.org.jm/wp-content/uploads/2022/12/isoiec31010.pdf?utm_source=chatgpt.com "IEC/ISO 31010"
[4]: https://assets.iec.ch/public/acos/IEC%2061508%20%26%20Functional%20Safety-2022.pdf?2023040501=&utm_source=chatgpt.com "Overview of IEC 61508 & Functional Safety"
[5]: https://www.osha.gov/sites/default/files/Hierarchy_of_Controls_02.01.23_form_508_2.pdf?utm_source=chatgpt.com "Identifying Hazard Control Options: The Hierarchy of Controls"
[6]: https://www.hse.gov.uk/foi/internalops/hid_circs/permissioning/spc_perm_37/?utm_source=chatgpt.com "Guidance on ALARP Decisions in COMAH"
